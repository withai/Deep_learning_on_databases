{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing modules and data\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /temp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /temp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /temp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /temp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# download and extract data from mnist database\n",
    "# one hot classifies the data ex : for \"1\" [1,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "mnist = input_data.read_data_sets('/temp/data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#neural network model\n",
    "\n",
    "#number of nodes\n",
    "image_size = 28\n",
    "batch_size = 100\n",
    "hidden_1_nodes = 500\n",
    "total_class = 10\n",
    "#hyperParam_l2 = 1e-2\n",
    "\n",
    "#graph = tf.Graph()\n",
    "#with graph.as_default():\n",
    "    \n",
    "#input dataset to the model\n",
    "tf_train_datasets = tf.placeholder(tf.float32, [None, image_size * image_size])\n",
    "tf_train_labels = tf.placeholder(tf.float32, [None, total_class])\n",
    "hyperParam_l2 = tf.placeholder(tf.float32)\n",
    "\n",
    "#input layer\n",
    "input_layer_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_1_nodes]))\n",
    "input_layer_biases = tf.Variable(tf.zeros([hidden_1_nodes]))\n",
    "\n",
    "input_layer_logit = tf.add(tf.matmul(tf_train_datasets, input_layer_weights), input_layer_biases)\n",
    "input_layer_logit = tf.nn.relu(input_layer_logit)\n",
    "\n",
    "#first hidden layer\n",
    "hidden_1_weights = tf.Variable(tf.truncated_normal([hidden_1_nodes, total_class]))\n",
    "hidden_1_biases = tf.Variable(tf.zeros([total_class]))\n",
    "\n",
    "hidden_1_logit = tf.add(tf.matmul(input_layer_logit, hidden_1_weights), hidden_1_biases)\n",
    "\n",
    "#cost function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = tf_train_labels, logits = hidden_1_logit)) \\\n",
    "         + hyperParam_l2 * (tf.nn.l2_loss(input_layer_weights) + tf.nn.l2_loss(hidden_1_weights))\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "#prediciton\n",
    "correct_pred = tf.equal(tf.argmax(hidden_1_logit, 1), tf.argmax(tf_train_labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, step 0, training accuracy 0.07\n",
      "epoch 0, step 100, training accuracy 0.7\n",
      "epoch 0, step 200, training accuracy 0.8\n",
      "epoch 0, step 300, training accuracy 0.76\n",
      "epoch 0, step 400, training accuracy 0.85\n",
      "epoch 0, step 500, training accuracy 0.81\n",
      "epoch 1, step 0, training accuracy 0.93\n",
      "epoch 1, step 100, training accuracy 0.91\n",
      "epoch 1, step 200, training accuracy 0.85\n",
      "epoch 1, step 300, training accuracy 0.87\n",
      "epoch 1, step 400, training accuracy 0.84\n",
      "epoch 1, step 500, training accuracy 0.92\n",
      "epoch 2, step 0, training accuracy 0.94\n",
      "epoch 2, step 100, training accuracy 0.9\n",
      "epoch 2, step 200, training accuracy 0.89\n",
      "epoch 2, step 300, training accuracy 0.8\n",
      "epoch 2, step 400, training accuracy 0.9\n",
      "epoch 2, step 500, training accuracy 0.93\n",
      "epoch 3, step 0, training accuracy 0.88\n",
      "epoch 3, step 100, training accuracy 0.94\n",
      "epoch 3, step 200, training accuracy 0.92\n",
      "epoch 3, step 300, training accuracy 0.92\n",
      "epoch 3, step 400, training accuracy 0.9\n",
      "epoch 3, step 500, training accuracy 0.83\n",
      "epoch 4, step 0, training accuracy 0.93\n",
      "epoch 4, step 100, training accuracy 0.9\n",
      "epoch 4, step 200, training accuracy 0.86\n",
      "epoch 4, step 300, training accuracy 0.97\n",
      "epoch 4, step 400, training accuracy 0.96\n",
      "epoch 4, step 500, training accuracy 0.93\n",
      "epoch 5, step 0, training accuracy 0.92\n",
      "epoch 5, step 100, training accuracy 0.97\n",
      "epoch 5, step 200, training accuracy 0.93\n",
      "epoch 5, step 300, training accuracy 0.97\n",
      "epoch 5, step 400, training accuracy 0.94\n",
      "epoch 5, step 500, training accuracy 0.93\n",
      "epoch 6, step 0, training accuracy 0.94\n",
      "epoch 6, step 100, training accuracy 0.96\n",
      "epoch 6, step 200, training accuracy 0.96\n",
      "epoch 6, step 300, training accuracy 0.93\n",
      "epoch 6, step 400, training accuracy 0.94\n",
      "epoch 6, step 500, training accuracy 0.97\n",
      "epoch 7, step 0, training accuracy 0.97\n",
      "epoch 7, step 100, training accuracy 0.92\n",
      "epoch 7, step 200, training accuracy 0.93\n",
      "epoch 7, step 300, training accuracy 0.93\n",
      "epoch 7, step 400, training accuracy 0.93\n",
      "epoch 7, step 500, training accuracy 0.93\n",
      "epoch 8, step 0, training accuracy 0.96\n",
      "epoch 8, step 100, training accuracy 0.96\n",
      "epoch 8, step 200, training accuracy 0.95\n",
      "epoch 8, step 300, training accuracy 0.94\n",
      "epoch 8, step 400, training accuracy 0.95\n",
      "epoch 8, step 500, training accuracy 0.96\n",
      "epoch 9, step 0, training accuracy 0.93\n",
      "epoch 9, step 100, training accuracy 0.98\n",
      "epoch 9, step 200, training accuracy 0.93\n",
      "epoch 9, step 300, training accuracy 0.98\n",
      "epoch 9, step 400, training accuracy 0.98\n",
      "epoch 9, step 500, training accuracy 0.92\n",
      "epoch 10, step 0, training accuracy 0.95\n",
      "epoch 10, step 100, training accuracy 0.98\n",
      "epoch 10, step 200, training accuracy 0.93\n",
      "epoch 10, step 300, training accuracy 0.95\n",
      "epoch 10, step 400, training accuracy 0.96\n",
      "epoch 10, step 500, training accuracy 0.98\n",
      "epoch 11, step 0, training accuracy 0.95\n",
      "epoch 11, step 100, training accuracy 0.95\n",
      "epoch 11, step 200, training accuracy 0.94\n",
      "epoch 11, step 300, training accuracy 1\n",
      "epoch 11, step 400, training accuracy 0.95\n",
      "epoch 11, step 500, training accuracy 0.96\n",
      "epoch 12, step 0, training accuracy 0.95\n",
      "epoch 12, step 100, training accuracy 0.94\n",
      "epoch 12, step 200, training accuracy 0.97\n",
      "epoch 12, step 300, training accuracy 0.96\n",
      "epoch 12, step 400, training accuracy 0.97\n",
      "epoch 12, step 500, training accuracy 0.94\n",
      "epoch 13, step 0, training accuracy 0.97\n",
      "epoch 13, step 100, training accuracy 0.92\n",
      "epoch 13, step 200, training accuracy 0.94\n",
      "epoch 13, step 300, training accuracy 0.94\n",
      "epoch 13, step 400, training accuracy 0.93\n",
      "epoch 13, step 500, training accuracy 0.93\n",
      "epoch 14, step 0, training accuracy 0.96\n",
      "epoch 14, step 100, training accuracy 0.93\n",
      "epoch 14, step 200, training accuracy 0.9\n",
      "epoch 14, step 300, training accuracy 0.96\n",
      "epoch 14, step 400, training accuracy 0.96\n",
      "epoch 14, step 500, training accuracy 0.94\n",
      "test accuracy 0.9441\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    for i in range(int(mnist.train.num_examples/batch_size)):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        sess.run([optimizer], feed_dict = {tf_train_datasets: batch[0], tf_train_labels: batch[1]})\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={tf_train_datasets:batch[0], tf_train_labels: batch[1]})\n",
    "            print(\"epoch %d, step %d, training accuracy %g\"%(epoch, i, train_accuracy))\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={tf_train_datasets: mnist.test.images, tf_train_labels: mnist.test.labels}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, step 0, training accuracy 0.08\n",
      "epoch 14, step 100, training accuracy 0.59\n",
      "epoch 14, step 200, training accuracy 0.79\n",
      "epoch 14, step 300, training accuracy 0.79\n",
      "epoch 14, step 400, training accuracy 0.85\n",
      "epoch 14, step 500, training accuracy 0.87\n",
      "epoch 14, step 0, training accuracy 0.81\n",
      "epoch 14, step 100, training accuracy 0.89\n",
      "epoch 14, step 200, training accuracy 0.89\n",
      "epoch 14, step 300, training accuracy 0.94\n",
      "epoch 14, step 400, training accuracy 0.89\n",
      "epoch 14, step 500, training accuracy 0.89\n",
      "epoch 14, step 0, training accuracy 0.91\n",
      "epoch 14, step 100, training accuracy 0.96\n",
      "epoch 14, step 200, training accuracy 0.98\n",
      "epoch 14, step 300, training accuracy 0.95\n",
      "epoch 14, step 400, training accuracy 0.95\n",
      "epoch 14, step 500, training accuracy 0.91\n",
      "epoch 14, step 0, training accuracy 0.91\n",
      "epoch 14, step 100, training accuracy 0.97\n",
      "epoch 14, step 200, training accuracy 0.9\n",
      "epoch 14, step 300, training accuracy 0.95\n",
      "epoch 14, step 400, training accuracy 0.95\n",
      "epoch 14, step 500, training accuracy 0.93\n",
      "epoch 14, step 0, training accuracy 0.91\n",
      "epoch 14, step 100, training accuracy 0.96\n",
      "epoch 14, step 200, training accuracy 0.89\n",
      "epoch 14, step 300, training accuracy 0.96\n",
      "epoch 14, step 400, training accuracy 0.97\n",
      "epoch 14, step 500, training accuracy 0.97\n",
      "epoch 14, step 0, training accuracy 0.96\n",
      "epoch 14, step 100, training accuracy 0.95\n",
      "epoch 14, step 200, training accuracy 0.97\n",
      "epoch 14, step 300, training accuracy 0.95\n",
      "epoch 14, step 400, training accuracy 0.98\n",
      "epoch 14, step 500, training accuracy 0.99\n",
      "epoch 14, step 0, training accuracy 0.98\n",
      "epoch 14, step 100, training accuracy 0.99\n",
      "epoch 14, step 200, training accuracy 0.96\n",
      "epoch 14, step 300, training accuracy 0.97\n",
      "epoch 14, step 400, training accuracy 0.98\n",
      "epoch 14, step 500, training accuracy 0.98\n",
      "epoch 14, step 0, training accuracy 0.94\n",
      "epoch 14, step 100, training accuracy 0.98\n",
      "epoch 14, step 200, training accuracy 0.99\n",
      "epoch 14, step 300, training accuracy 0.98\n",
      "epoch 14, step 400, training accuracy 0.97\n",
      "epoch 14, step 500, training accuracy 0.96\n",
      "epoch 14, step 0, training accuracy 0.96\n",
      "epoch 14, step 100, training accuracy 0.99\n",
      "epoch 14, step 200, training accuracy 0.97\n",
      "epoch 14, step 300, training accuracy 0.97\n",
      "epoch 14, step 400, training accuracy 0.98\n",
      "epoch 14, step 500, training accuracy 0.97\n",
      "epoch 14, step 0, training accuracy 0.96\n",
      "epoch 14, step 100, training accuracy 0.99\n",
      "epoch 14, step 200, training accuracy 0.96\n",
      "epoch 14, step 300, training accuracy 0.98\n",
      "epoch 14, step 400, training accuracy 0.99\n",
      "epoch 14, step 500, training accuracy 0.99\n",
      "epoch 14, step 0, training accuracy 0.99\n",
      "epoch 14, step 100, training accuracy 0.99\n",
      "epoch 14, step 200, training accuracy 0.98\n",
      "epoch 14, step 300, training accuracy 0.99\n",
      "epoch 14, step 400, training accuracy 0.99\n",
      "epoch 14, step 500, training accuracy 0.94\n",
      "epoch 14, step 0, training accuracy 0.96\n",
      "epoch 14, step 100, training accuracy 1\n",
      "epoch 14, step 200, training accuracy 0.98\n",
      "epoch 14, step 300, training accuracy 0.99\n",
      "epoch 14, step 400, training accuracy 0.98\n",
      "epoch 14, step 500, training accuracy 0.98\n",
      "epoch 14, step 0, training accuracy 0.99\n",
      "epoch 14, step 100, training accuracy 0.97\n",
      "epoch 14, step 200, training accuracy 0.99\n",
      "epoch 14, step 300, training accuracy 0.99\n",
      "epoch 14, step 400, training accuracy 0.96\n",
      "epoch 14, step 500, training accuracy 0.96\n",
      "epoch 14, step 0, training accuracy 0.97\n",
      "epoch 14, step 100, training accuracy 0.96\n",
      "epoch 14, step 200, training accuracy 0.99\n",
      "epoch 14, step 300, training accuracy 1\n",
      "epoch 14, step 400, training accuracy 0.98\n",
      "epoch 14, step 500, training accuracy 0.97\n",
      "epoch 14, step 0, training accuracy 0.97\n",
      "epoch 14, step 100, training accuracy 0.97\n",
      "epoch 14, step 200, training accuracy 1\n",
      "epoch 14, step 300, training accuracy 0.98\n",
      "epoch 14, step 400, training accuracy 0.99\n",
      "epoch 14, step 500, training accuracy 0.97\n",
      "epoch 14, step 0, training accuracy 1\n",
      "epoch 14, step 100, training accuracy 0.98\n",
      "epoch 14, step 200, training accuracy 0.96\n",
      "epoch 14, step 300, training accuracy 0.95\n",
      "epoch 14, step 400, training accuracy 0.98\n",
      "epoch 14, step 500, training accuracy 0.99\n",
      "epoch 14, step 0, training accuracy 0.97\n",
      "epoch 14, step 100, training accuracy 0.99\n",
      "epoch 14, step 200, training accuracy 0.94\n",
      "epoch 14, step 300, training accuracy 0.97\n",
      "epoch 14, step 400, training accuracy 0.97\n",
      "epoch 14, step 500, training accuracy 0.96\n",
      "epoch 14, step 0, training accuracy 0.97\n",
      "epoch 14, step 100, training accuracy 0.98\n",
      "epoch 14, step 200, training accuracy 0.99\n",
      "epoch 14, step 300, training accuracy 0.98\n",
      "epoch 14, step 400, training accuracy 0.98\n",
      "epoch 14, step 500, training accuracy 0.93\n",
      "epoch 14, step 0, training accuracy 0.96\n",
      "epoch 14, step 100, training accuracy 0.98\n",
      "epoch 14, step 200, training accuracy 0.98\n",
      "epoch 14, step 300, training accuracy 0.94\n",
      "epoch 14, step 400, training accuracy 0.98\n",
      "epoch 14, step 500, training accuracy 0.97\n",
      "epoch 14, step 0, training accuracy 0.97\n",
      "epoch 14, step 100, training accuracy 0.95\n",
      "epoch 14, step 200, training accuracy 0.97\n",
      "epoch 14, step 300, training accuracy 1\n",
      "epoch 14, step 400, training accuracy 0.94\n",
      "epoch 14, step 500, training accuracy 0.97\n",
      "epoch 14, step 0, training accuracy 0.95\n",
      "epoch 14, step 100, training accuracy 0.95\n",
      "epoch 14, step 200, training accuracy 0.96\n",
      "epoch 14, step 300, training accuracy 0.96\n",
      "epoch 14, step 400, training accuracy 0.96\n",
      "epoch 14, step 500, training accuracy 0.97\n",
      "epoch 14, step 0, training accuracy 0.97\n",
      "epoch 14, step 100, training accuracy 0.96\n",
      "epoch 14, step 200, training accuracy 0.93\n",
      "epoch 14, step 300, training accuracy 0.95\n",
      "epoch 14, step 400, training accuracy 0.93\n",
      "epoch 14, step 500, training accuracy 0.98\n",
      "epoch 14, step 0, training accuracy 0.91\n",
      "epoch 14, step 100, training accuracy 0.94\n",
      "epoch 14, step 200, training accuracy 0.93\n",
      "epoch 14, step 300, training accuracy 0.94\n",
      "epoch 14, step 400, training accuracy 0.93\n",
      "epoch 14, step 500, training accuracy 0.92\n",
      "epoch 14, step 0, training accuracy 0.95\n",
      "epoch 14, step 100, training accuracy 0.97\n",
      "epoch 14, step 200, training accuracy 0.92\n",
      "epoch 14, step 300, training accuracy 0.87\n",
      "epoch 14, step 400, training accuracy 0.87\n",
      "epoch 14, step 500, training accuracy 0.92\n",
      "epoch 14, step 0, training accuracy 0.88\n",
      "epoch 14, step 100, training accuracy 0.88\n",
      "epoch 14, step 200, training accuracy 0.9\n",
      "epoch 14, step 300, training accuracy 0.88\n",
      "epoch 14, step 400, training accuracy 0.91\n",
      "epoch 14, step 500, training accuracy 0.91\n",
      "epoch 14, step 0, training accuracy 0.91\n",
      "epoch 14, step 100, training accuracy 0.93\n",
      "epoch 14, step 200, training accuracy 0.85\n",
      "epoch 14, step 300, training accuracy 0.9\n",
      "epoch 14, step 400, training accuracy 0.88\n",
      "epoch 14, step 500, training accuracy 0.87\n",
      "epoch 14, step 0, training accuracy 0.89\n",
      "epoch 14, step 100, training accuracy 0.84\n",
      "epoch 14, step 200, training accuracy 0.91\n",
      "epoch 14, step 300, training accuracy 0.87\n",
      "epoch 14, step 400, training accuracy 0.84\n",
      "epoch 14, step 500, training accuracy 0.85\n",
      "epoch 14, step 0, training accuracy 0.86\n",
      "epoch 14, step 100, training accuracy 0.84\n",
      "epoch 14, step 200, training accuracy 0.85\n",
      "epoch 14, step 300, training accuracy 0.9\n",
      "epoch 14, step 400, training accuracy 0.89\n",
      "epoch 14, step 500, training accuracy 0.82\n",
      "epoch 14, step 0, training accuracy 0.92\n",
      "epoch 14, step 100, training accuracy 0.84\n",
      "epoch 14, step 200, training accuracy 0.9\n",
      "epoch 14, step 300, training accuracy 0.86\n",
      "epoch 14, step 400, training accuracy 0.86\n",
      "epoch 14, step 500, training accuracy 0.91\n",
      "epoch 14, step 0, training accuracy 0.88\n",
      "epoch 14, step 100, training accuracy 0.89\n",
      "epoch 14, step 200, training accuracy 0.86\n",
      "epoch 14, step 300, training accuracy 0.91\n",
      "epoch 14, step 400, training accuracy 0.85\n",
      "epoch 14, step 500, training accuracy 0.89\n"
     ]
    }
   ],
   "source": [
    "l2_reg_values = [pow(10, i) for i in np.arange(-4, -1, 0.1)]\n",
    "accuracy_values = []\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "epochs = 15\n",
    "\n",
    "for l2_reg_value in l2_reg_values:\n",
    "    for i in range(int(mnist.train.num_examples/batch_size)):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        sess.run([optimizer], feed_dict = {tf_train_datasets: batch[0], tf_train_labels: batch[1], hyperParam_l2: l2_reg_value})\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={tf_train_datasets:batch[0], tf_train_labels: batch[1], hyperParam_l2: l2_reg_value})\n",
    "            print(\"epoch %d, step %d, training accuracy %g\"%(epoch, i, train_accuracy))\n",
    "\n",
    "    accuracy_values.append(accuracy.eval(feed_dict={tf_train_datasets: mnist.test.images, tf_train_labels: mnist.test.labels, hyperParam_l2: l2_reg_value}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28f85766978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(l2_reg_values, accuracy_values)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9555\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    for i in range(int(mnist.train.num_examples/batch_size)):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        sess.run([optimizer], feed_dict = {tf_train_datasets: batch[0], tf_train_labels: batch[1], hyperParam_l2: 1e-21/10})\n",
    "        '''if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={tf_train_datasets:batch[0], tf_train_labels: batch[1], hyperParam_l2: 1e-3})\n",
    "            print(\"epoch %d, step %d, training accuracy %g\"%(epoch, i, train_accuracy))\n",
    "        '''\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={tf_train_datasets: mnist.test.images, tf_train_labels: mnist.test.labels, hyperParam_l2: 1e-3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#neural network model\n",
    "\n",
    "#number of nodes\n",
    "image_size = 28\n",
    "batch_size = 100\n",
    "hidden_1_nodes = 500\n",
    "total_class = 10\n",
    "#hyperParam_l2 = 1e-2\n",
    "\n",
    "#graph = tf.Graph()\n",
    "#with graph.as_default():\n",
    "    \n",
    "#input dataset to the model\n",
    "tf_train_datasets = tf.placeholder(tf.float32, [None, image_size * image_size])\n",
    "tf_train_labels = tf.placeholder(tf.float32, [None, total_class])\n",
    "hyperParam_l2 = tf.placeholder(tf.float32)\n",
    "\n",
    "#input layer\n",
    "input_layer_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_1_nodes]))\n",
    "input_layer_biases = tf.Variable(tf.zeros([hidden_1_nodes]))\n",
    "\n",
    "input_layer_logit = tf.add(tf.matmul(tf_train_datasets, input_layer_weights), input_layer_biases)\n",
    "input_layer_logit = tf.nn.relu(input_layer_logit)\n",
    "input_layer_logit = tf.nn.droupout(input_layer_logit, 0.5)\n",
    "\n",
    "#first hidden layer\n",
    "hidden_1_weights = tf.Variable(tf.truncated_normal([hidden_1_nodes, total_class]))\n",
    "hidden_1_biases = tf.Variable(tf.zeros([total_class]))\n",
    "\n",
    "hidden_1_logit = tf.add(tf.matmul(input_layer_logit, hidden_1_weights), hidden_1_biases)\n",
    "\n",
    "#cost function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = tf_train_labels, logits = hidden_1_logit)) \\\n",
    "         + hyperParam_l2 * (tf.nn.l2_loss(input_layer_weights) + tf.nn.l2_loss(hidden_1_weights))\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "#prediciton\n",
    "correct_pred = tf.equal(tf.argmax(hidden_1_logit, 1), tf.argmax(tf_train_labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9607\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    for i in range(int(mnist.train.num_examples/batch_size)):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        sess.run([optimizer], feed_dict = {tf_train_datasets: batch[0], tf_train_labels: batch[1], hyperParam_l2: 1e-21/10})\n",
    "        '''if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={tf_train_datasets:batch[0], tf_train_labels: batch[1], hyperParam_l2: 1e-3})\n",
    "            print(\"epoch %d, step %d, training accuracy %g\"%(epoch, i, train_accuracy))\n",
    "        '''\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={tf_train_datasets: mnist.test.images, tf_train_labels: mnist.test.labels, hyperParam_l2: 1e-21/10}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
